 {
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from __future__ import annotations"
      ],
      "metadata": {
        "id": "h5zBCJ-ZW9WP"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial"
      ],
      "metadata": {
        "id": "51_PoHUP0VK_"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "lIYdn1woOS1n"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from torchvision.ops.misc import Conv2dNormActivation\n",
        "\n",
        "from typing import NamedTuple"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hl_fm = torch.randn(size=(1, 512, 13, 13))\n",
        "ml_fm = torch.randn(size=(1, 256, 26, 26))"
      ],
      "metadata": {
        "id": "xEzZbm9WsPZN"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.add(hl_fm, ml_fm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144
        },
        "id": "HvqBygsFss4L",
        "outputId": "c62c6406-1349-42e9-b773-191d7f6fe99a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (13) must match the size of tensor b (26) at non-singleton dimension 3",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-b960734b1c29>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhl_fm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_fm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (13) must match the size of tensor b (26) at non-singleton dimension 3"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hl_fm = torch.randn(size=(1, 512, 26, 26))\n",
        "ml_fm = torch.randn(size=(1, 256, 26, 26))\n",
        "\n",
        "torch.add(hl_fm, ml_fm)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 179
        },
        "id": "jPDRlkcqsxkZ",
        "outputId": "4ee7f128-a041-4c31-c028-ee0ef7b60acb"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "The size of tensor a (512) must match the size of tensor b (256) at non-singleton dimension 1",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-a94467607215>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mml_fm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m256\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m26\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhl_fm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mml_fm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (512) must match the size of tensor b (256) at non-singleton dimension 1"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from functools import partial\n",
        "from torchvision.ops.misc import Conv2dNormActivation\n",
        "\n",
        "LeakyRelu_Inplace = partial(\n",
        "    nn.LeakyReLU,\n",
        "    negative_slope=0.1,\n",
        "    inplace=True,\n",
        ")\n",
        "ConvBlockReduceChannels = partial(Conv2dNormActivation,\n",
        "                                  kernel_size=1,\n",
        "                                  activation_layer=LeakyRelu_Inplace)"
      ],
      "metadata": {
        "id": "7kBEpK9Gxncz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hl_fm = torch.randn(size=(1, 512, 13, 13))\n",
        "ml_fm = torch.randn(size=(1, 256, 26, 26))\n",
        "ll_fm = torch.randn(size=(1, 128, 52, 52))"
      ],
      "metadata": {
        "id": "Jawf7eDex-y5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "conv_hl_reduce = ConvBlockReduceChannels(in_channels=512, out_channels=64)\n",
        "conv_ml_reduce = ConvBlockReduceChannels(in_channels=256, out_channels=64)\n",
        "conv_ll_reduce = ConvBlockReduceChannels(in_channels=128, out_channels=64)"
      ],
      "metadata": {
        "id": "qjvAaKDYyGXQ"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hl_fm_r = conv_hl_reduce(hl_fm)\n",
        "ml_fm_r = conv_ml_reduce(ml_fm)\n",
        "ll_fm_r = conv_ll_reduce(ll_fm)"
      ],
      "metadata": {
        "id": "PqJlamrzyUSe"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"New HL shape - {hl_fm_r.shape}\")\n",
        "print(f\"New ML shape - {ml_fm_r.shape}\")\n",
        "print(f\"New LL shape - {ll_fm_r.shape}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9XqKM1byjKF",
        "outputId": "388b523f-3ebe-4cf0-f89d-39d270b8c662"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "New HL shape - torch.Size([1, 64, 13, 13])\n",
            "New ML shape - torch.Size([1, 64, 26, 26])\n",
            "New LL shape - torch.Size([1, 64, 52, 52])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hl_upsampler = nn.Upsample(scale_factor=2, mode=\"nearest\")"
      ],
      "metadata": {
        "id": "Hhb8ienyy5ON"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hl_fm_r_upsampled = hl_upsampler(hl_fm_r)\n",
        "\n",
        "hl_fm_r_upsampled.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RZw6A5YPzR2P",
        "outputId": "74ea6f08-58ba-43f1-9caf-357454e3c01a"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "hl_ml_fused = torch.add(hl_fm_r_upsampled, ml_fm_r)\n",
        "\n",
        "hl_ml_fused.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "42P54zILzqoU",
        "outputId": "4b1d5193-69b5-458f-c052-147bbb2b6a78"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ConvSmoother = partial(\n",
        "                Conv2dNormActivation,\n",
        "                  in_channels=64,\n",
        "                  out_channels=64,\n",
        "                  kernel_size=3,\n",
        "                  activation_layer=LeakyRelu_Inplace\n",
        "               )\n",
        "\n",
        "hl_ml_fused_smoother = ConvSmoother()\n",
        "\n",
        "smooth_hl_ml_fused = hl_ml_fused_smoother(hl_ml_fused)\n",
        "\n",
        "print(smooth_hl_ml_fused.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBGSfzgo7El2",
        "outputId": "1040ea3d-7120-459e-a4f7-65f7a51f5a59"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 64, 26, 26])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeBackboneResult(NamedTuple):\n",
        "  hl_features: torch.Tensor\n",
        "  ml_features: torch.Tensor\n",
        "  ll_features: torch.Tensor"
      ],
      "metadata": {
        "id": "8tAwXXwkPOdR"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeBackbone(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "\n",
        "  def forward(self, x: torch.Tensor) -> FakeBackboneResult:\n",
        "    hl_fm = torch.randn(size=(1, 512, 13, 13))\n",
        "    ml_fm = torch.randn(size=(1, 256, 26, 26))\n",
        "    ll_fm = torch.randn(size=(1, 128, 52, 52))\n",
        "\n",
        "    return FakeBackboneResult(\n",
        "        hl_features=hl_fm,\n",
        "        ml_features=ml_fm,\n",
        "        ll_features=ll_fm\n",
        "    )"
      ],
      "metadata": {
        "id": "m3W1-FcKWtoL"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FPNNeck(nn.Module):\n",
        "  def __init__(self, in_channels: list[int], out_channels: int):\n",
        "    super().__init__()\n",
        "\n",
        "    LeakyRelu_Inplace = partial(\n",
        "        nn.LeakyReLU,\n",
        "        negative_slope=0.1,\n",
        "        inplace=True,\n",
        "    )\n",
        "\n",
        "    ConvBlock = partial(Conv2dNormActivation, activation_layer=LeakyRelu_Inplace)\n",
        "\n",
        "    self.hl_channel_reducer = ConvBlock(\n",
        "        in_channels=in_channels[0],\n",
        "        out_channels=out_channels,\n",
        "        kernel_size=1,\n",
        "    )\n",
        "\n",
        "    self.ml_channel_reducer = ConvBlock(\n",
        "        in_channels=in_channels[1],\n",
        "        out_channels=out_channels,\n",
        "        kernel_size=1,\n",
        "    )\n",
        "\n",
        "    self.ll_channel_reducer = ConvBlock(\n",
        "        in_channels=in_channels[2],\n",
        "        out_channels=out_channels,\n",
        "        kernel_size=1,\n",
        "    )\n",
        "\n",
        "    self.ml_smoother = ConvBlock(\n",
        "        in_channels=out_channels,\n",
        "        out_channels=out_channels,\n",
        "    )\n",
        "\n",
        "    self.ll_smoother = ConvBlock(\n",
        "        in_channels=out_channels,\n",
        "        out_channels=out_channels,\n",
        "    )\n",
        "\n",
        "  def forward(self,\n",
        "              hl_features:torch.Tensor,\n",
        "              ml_features:torch.Tensor,\n",
        "              ll_features:torch.Tensor):\n",
        "\n",
        "    hl_channel_r = self.hl_channel_reducer(hl_features)\n",
        "    ml_channel_r = self.ml_channel_reducer(ml_features)\n",
        "    ll_channel_r = self.ll_channel_reducer(ll_features)\n",
        "\n",
        "    upsample_hl = F.interpolate(\n",
        "        hl_channel_r,\n",
        "        size=[ml_channel_r.size(2), ml_channel_r.size(3)],\n",
        "        mode=\"nearest\",\n",
        "    )\n",
        "\n",
        "    fused_hl_ml = upsample_hl + ml_channel_r\n",
        "    smoothed_ml_features = self.ml_smoother(fused_hl_ml)\n",
        "\n",
        "    upsample_ml = F.interpolate(\n",
        "        smoothed_ml_features,\n",
        "        size=[ll_channel_r.size(2), ll_channel_r.size(3)],\n",
        "        mode=\"nearest\",\n",
        "    )\n",
        "    fused_ml_ll = upsample_ml + ll_channel_r\n",
        "    smoothed_ll_features = self.ll_smoother(fused_ml_ll)\n",
        "\n",
        "    out = [hl_channel_r, smoothed_ml_features, smoothed_ll_features]\n",
        "    return out\n"
      ],
      "metadata": {
        "id": "uf2uebjizzMb"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neck = FPNNeck(in_channels=[512, 256, 128], out_channels=64)"
      ],
      "metadata": {
        "id": "9oNW80tNCxmI"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "backbone = FakeBackbone()\n",
        "\n",
        "backbone_output = backbone(torch.randn(size=(1, 3, 416, 416)))"
      ],
      "metadata": {
        "id": "FzNrtyMaXApH"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_hl_features, enriched_ml_features, enriched_ll_features = neck(backbone_output.hl_features,\n",
        "     backbone_output.ml_features,\n",
        "     backbone_output.ll_features)"
      ],
      "metadata": {
        "id": "bcUSsMV9C6vm"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_hl_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ksuwhx33DRbx",
        "outputId": "72fa3eed-3732-4abc-de6a-a34ddc652879"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 13, 13])"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_ml_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hCM8IGWXDS6w",
        "outputId": "da5e9eff-3bf3-40b6-d973-177ad21c5329"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 26, 26])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "enriched_ll_features.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7v06m7lcDUO3",
        "outputId": "c4cdea2f-4f8b-4253-851c-ad365fb95b18"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 64, 52, 52])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "QSCYngs2DV0a"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
